# LangChain è¯¦ç»†å­¦ä¹ è®¡åˆ’ï¼ˆ20 å‘¨ï¼‰

## ğŸ“… æ•´ä½“è®¡åˆ’æ¦‚è§ˆ

| é˜¶æ®µ | å‘¨æ•° | ä¸»é¢˜ | ç›®æ ‡ |
|------|------|------|------|
| ç¬¬ä¸€é˜¶æ®µ | 1-2 | åŸºç¡€æ¦‚å¿µ | ç†è§£ LangChain æ¶æ„å’Œæ ¸å¿ƒæ¦‚å¿µ |
| ç¬¬äºŒé˜¶æ®µ | 3-4 | é“¾ä¸ç»„åˆ | æŒæ¡ LCEL å’Œ Runnable |
| ç¬¬ä¸‰é˜¶æ®µ | 5-7 | æ•°æ®ç®¡ç†ä¸ RAG | æ„å»ºå®Œæ•´ RAG ç³»ç»Ÿ |
| ç¬¬å››é˜¶æ®µ | 8-10 | å·¥å…·ä¸ä»£ç† | å®ç°è‡ªä¸»ä»£ç† |
| ç¬¬äº”é˜¶æ®µ | 11-13 | LangGraph | æŒæ¡å›¾å½¢ç¼–æ’ |
| ç¬¬å…­é˜¶æ®µ | 14-16 | é«˜çº§åº”ç”¨ | å®ç°å¤šä»£ç†ã€æµå¼ã€å¼‚æ­¥ |
| ç¬¬ä¸ƒé˜¶æ®µ | 17-20 | ç»¼åˆé¡¹ç›® | å®Œæˆå®Œæ•´é¡¹ç›® |

---

## ğŸ“š ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€æ¦‚å¿µï¼ˆç¬¬ 1-2 å‘¨ï¼‰

### ç¬¬ 1 å‘¨ï¼šæ ¸å¿ƒæ¦‚å¿µä¸æ¨¡å‹é›†æˆ

#### å‘¨ä¸€ - ç¯å¢ƒå‡†å¤‡ä¸æ¶æ„ç†è§£ (3 å°æ—¶)
```
ä»»åŠ¡æ¸…å•:
â–¡ äº†è§£ LangChain å‘å±•å†ç¨‹
  - é˜…è¯»å®˜æ–¹ä»‹ç»æ–‡æ¡£ (30 åˆ†é’Ÿ)
  - è§‚çœ‹é¡¹ç›®ç»“æ„è®²è§£è§†é¢‘ (30 åˆ†é’Ÿ)

â–¡ ç†è§£ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—
  - langchain-core: åŸºç¡€æŠ½è±¡ (30 åˆ†é’Ÿ)
  - langchain-community: ç¬¬ä¸‰æ–¹é›†æˆ (20 åˆ†é’Ÿ)
  - langchain: é«˜çº§é“¾ (20 åˆ†é’Ÿ)

â–¡ è®¾ç½®å¼€å‘ç¯å¢ƒ
  - åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ (10 åˆ†é’Ÿ)
  - å®‰è£…ä¾èµ–åŒ… (10 åˆ†é’Ÿ)
  - éªŒè¯å®‰è£… (10 åˆ†é’Ÿ)

å­¦ä¹ èµ„æº:
- https://python.langchain.com/docs/get_started/introduction
- https://github.com/langchain-ai/langchain
```

#### å‘¨äºŒ - LLM é›†æˆåŸºç¡€ (3 å°æ—¶)
```
ä»»åŠ¡æ¸…å•:
â–¡ LLM ä¸ Chat Model çš„åŒºåˆ«
  - æ¥å£å¯¹æ¯” (30 åˆ†é’Ÿ)
  - ä½¿ç”¨åœºæ™¯åˆ†æ (30 åˆ†é’Ÿ)

â–¡ OpenAI é›†æˆ
  - è·å– API å¯†é’¥ (10 åˆ†é’Ÿ)
  - å®ç°ç¬¬ä¸€ä¸ª LLM è°ƒç”¨ (30 åˆ†é’Ÿ)
  - æµ‹è¯•ä¸åŒå‚æ•° (30 åˆ†é’Ÿ)

â–¡ å…¶ä»–æ¨¡å‹æ¢ç´¢
  - Anthropic Claude (20 åˆ†é’Ÿ)
  - æœ¬åœ°æ¨¡å‹ (Ollama) (20 åˆ†é’Ÿ)
  - æ¨¡å‹é€‰æ‹©æ ‡å‡† (20 åˆ†é’Ÿ)

ä»£ç ä»»åŠ¡:
```python
# åˆ›å»ºæ–‡ä»¶: 01_llm_basics.py
from langchain_openai import ChatOpenAI

model = ChatOpenAI(
    api_key="your-key",
    model="gpt-4",
    temperature=0.7
)

response = model.invoke("Hello!")
print(response.content)

# å®éªŒä¸åŒå‚æ•°
for temp in [0.0, 0.5, 1.0]:
    model = ChatOpenAI(temperature=temp)
    print(f"Temperature {temp}: {model.invoke('Write a poem').content}")
```

å­¦ä¹ èµ„æº:
- https://python.langchain.com/docs/integrations/llms/
- https://python.langchain.com/docs/integrations/chat/
```

#### å‘¨ä¸‰ - Prompt å·¥ç¨‹åŸºç¡€ (3 å°æ—¶)
```
ä»»åŠ¡æ¸…å•:
â–¡ Prompt è®¾è®¡åŸç†
  - æ¸…æ™°æŒ‡ä»¤ (30 åˆ†é’Ÿ)
  - ä¸Šä¸‹æ–‡æä¾› (30 åˆ†é’Ÿ)
  - è¾“å‡ºæ ¼å¼æŒ‡å®š (20 åˆ†é’Ÿ)

â–¡ PromptTemplate ä½¿ç”¨
  - åŸºç¡€æ¨¡æ¿ (30 åˆ†é’Ÿ)
  - å˜é‡æ›¿æ¢ (30 åˆ†é’Ÿ)
  - åŠ¨æ€æç¤ºç”Ÿæˆ (20 åˆ†é’Ÿ)

â–¡ ChatPromptTemplate
  - ç³»ç»Ÿæ¶ˆæ¯ (20 åˆ†é’Ÿ)
  - ç”¨æˆ·æ¶ˆæ¯ (20 åˆ†é’Ÿ)
  - å¤šè½®å¯¹è¯ (20 åˆ†é’Ÿ)

ä»£ç ä»»åŠ¡:
```python
# åˆ›å»ºæ–‡ä»¶: 02_prompt_templates.py
from langchain_core.prompts import PromptTemplate, ChatPromptTemplate

# åŸºç¡€æ¨¡æ¿
template = PromptTemplate(
    input_variables=["topic"],
    template="å†™ä¸€ç¯‡å…³äº {topic} çš„æ–‡ç« "
)
print(template.format(topic="Python"))

# Chat æ¨¡æ¿
chat_template = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªç¿»è¯‘åŠ©æ‰‹"),
    ("user", "ç¿»è¯‘: {text}")
])
print(chat_template.format_messages(text="Hello"))

# åŠ¨æ€æç¤º
few_shot_template = ChatPromptTemplate.from_messages([
    ("system", "æ ¹æ®ç¤ºä¾‹è¿›è¡Œç¿»è¯‘"),
    ("user", "ç¤ºä¾‹: {examples}"),
    ("user", "ç¿»è¯‘: {text}")
])
```

å­¦ä¹ èµ„æº:
- https://python.langchain.com/docs/concepts/prompt_templates
- Few-shot å­¦ä¹ : https://python.langchain.com/docs/concepts/prompting
```

#### å‘¨å›› - æ¶ˆæ¯ä¸è¾“å‡ºè§£æ (3 å°æ—¶)
```
ä»»åŠ¡æ¸…å•:
â–¡ Message ç³»ç»Ÿ
  - HumanMessage (20 åˆ†é’Ÿ)
  - AIMessage (20 åˆ†é’Ÿ)
  - SystemMessage (20 åˆ†é’Ÿ)
  - æ¶ˆæ¯è§’è‰²ä¸ä½œç”¨ (20 åˆ†é’Ÿ)

â–¡ è¾“å‡ºè§£æå™¨
  - StrOutputParser (30 åˆ†é’Ÿ)
  - JsonOutputParser (30 åˆ†é’Ÿ)
  - PydanticOutputParser (30 åˆ†é’Ÿ)

â–¡ é”™è¯¯å¤„ç†
  - è§£æå¤±è´¥å¤„ç† (20 åˆ†é’Ÿ)
  - é‡è¯•æœºåˆ¶ (20 åˆ†é’Ÿ)

ä»£ç ä»»åŠ¡:
```python
# åˆ›å»ºæ–‡ä»¶: 03_messages_parsing.py
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.output_parsers import JsonOutputParser, StrOutputParser
from pydantic import BaseModel

# æ¶ˆæ¯ä½¿ç”¨
messages = [
    SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä»£ç å®¡æŸ¥å¸ˆ"),
    HumanMessage(content="å®¡æŸ¥è¿™ä¸ªä»£ç "),
    AIMessage(content="ä»£ç çœ‹èµ·æ¥ä¸é”™")
]

# è¾“å‡ºè§£æ
class CodeReview(BaseModel):
    rating: int
    comments: str

parser = JsonOutputParser(pydantic_object=CodeReview)
model = ChatOpenAI()

prompt = ChatPromptTemplate.from_template("è¯„åˆ†: {code}")
chain = prompt | model | parser

result = chain.invoke({"code": "print('hello')"})
print(result)
```

å­¦ä¹ èµ„æº:
- https://python.langchain.com/docs/concepts/messages
- https://python.langchain.com/docs/concepts/output_parsers
```

#### å‘¨äº” - æœ¬å‘¨å›é¡¾ä¸å®è·µ (3 å°æ—¶)
```
ä»»åŠ¡æ¸…å•:
â–¡ å¤ä¹ æ ¸å¿ƒæ¦‚å¿µ
  - æ•´ç†ç¬”è®° (30 åˆ†é’Ÿ)
  - å›ç­”å…³é”®é—®é¢˜ (30 åˆ†é’Ÿ)
  - æ¦‚å¿µå¯¹æ¯” (20 åˆ†é’Ÿ)

â–¡ ç»¼åˆç»ƒä¹ 
  - åˆ›å»ºå¤šæ¨¡å‹è°ƒç”¨ç¨‹åº (30 åˆ†é’Ÿ)
  - å®ç°åŠ¨æ€æç¤ºç”Ÿæˆ (30 åˆ†é’Ÿ)
  - ç»„åˆè¾“å‡ºè§£æ (20 åˆ†é’Ÿ)

ç»¼åˆé¡¹ç›®:
```python
# åˆ›å»ºæ–‡ä»¶: 04_week1_project.py
"""
ä»»åŠ¡: æ„å»ºä¸€ä¸ª"æ™ºèƒ½ç¿»è¯‘æœº"
åŠŸèƒ½:
- æ”¯æŒå¤šç§ç›®æ ‡è¯­è¨€
- è¿”å›ç»“æ„åŒ–è¾“å‡º (åŸæ–‡ã€è¯‘æ–‡ã€éš¾åº¦è¯„åˆ†)
- å¤„ç†é•¿æ–‡æœ¬
"""

from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel

class TranslationResult(BaseModel):
    original: str
    translated: str
    difficulty: int  # 1-5

# å®ç°ç¿»è¯‘é“¾
```

å­¦ä¹ æ£€æŸ¥:
- â–¡ èƒ½è§£é‡Š LangChain çš„æ ¸å¿ƒä¼˜åŠ¿
- â–¡ èƒ½ä½¿ç”¨ ChatOpenAI è¿›è¡ŒåŸºç¡€è°ƒç”¨
- â–¡ èƒ½åˆ›å»º PromptTemplate å’Œ ChatPromptTemplate
- â–¡ èƒ½ä½¿ç”¨ OutputParser è§£æç»“æ„åŒ–æ•°æ®
- â–¡ èƒ½å¤„ç†åŸºç¡€é”™è¯¯æƒ…å†µ
```

### ç¬¬ 2 å‘¨ï¼šè¿›é˜¶æ¦‚å¿µä¸å®è·µ

#### å‘¨ä¸€ - æ¶ˆæ¯å†å²ä¸å¯¹è¯ (3 å°æ—¶)
```
ä»»åŠ¡æ¸…å•:
â–¡ ç»´æŠ¤å¯¹è¯å†å²
  - æ¶ˆæ¯åˆ—è¡¨ç®¡ç† (30 åˆ†é’Ÿ)
  - ä¸Šä¸‹æ–‡çª—å£ (30 åˆ†é’Ÿ)
  - æ¶ˆæ¯æ¸…ç†ç­–ç•¥ (20 åˆ†é’Ÿ)

â–¡ å®ç°å¤šè½®å¯¹è¯
  - çŠ¶æ€ç®¡ç† (30 åˆ†é’Ÿ)
  - è§’è‰²åˆ‡æ¢ (20 åˆ†é’Ÿ)
  - ä¸Šä¸‹æ–‡è¿è´¯æ€§ (20 åˆ†é’Ÿ)

ä»£ç ä»»åŠ¡:
```python
# åˆ›å»ºæ–‡ä»¶: 05_conversation.py
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_openai import ChatOpenAI

model = ChatOpenAI()

# æ„å»ºå¯¹è¯å†å²
messages = [
    SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹"),
    HumanMessage(content="ä½ å¥½"),
    AIMessage(content="ä½ å¥½!"),
    HumanMessage(content="ä½ å«ä»€ä¹ˆåå­—?"),
    AIMessage(content="æˆ‘æ˜¯ Claude çš„åŠ©æ‰‹")
]

# ç»§ç»­å¯¹è¯
messages.append(HumanMessage(content="ä½ èƒ½å¸®æˆ‘åšä»€ä¹ˆ?"))
response = model.invoke(messages)
messages.append(AIMessage(content=response.content))

print(response.content)
```
```

#### å‘¨äºŒ - æ¨¡å‹å‚æ•°ä¸æˆæœ¬è®¡ç®— (3 å°æ—¶)
```
ä»»åŠ¡æ¸…å•:
â–¡ æ¨¡å‹å‚æ•°è¯¦è§£
  - temperature (30 åˆ†é’Ÿ)
  - max_tokens (20 åˆ†é’Ÿ)
  - top_p (20 åˆ†é’Ÿ)
  - frequency_penalty (20 åˆ†é’Ÿ)

â–¡ Token ä¸æˆæœ¬
  - Token è®¡æ•° (30 åˆ†é’Ÿ)
  - æˆæœ¬ä¼°ç®— (30 åˆ†é’Ÿ)
  - æˆæœ¬ä¼˜åŒ– (20 åˆ†é’Ÿ)

ä»£ç ä»»åŠ¡:
```python
# åˆ›å»ºæ–‡ä»¶: 06_parameters_cost.py
from langchain_openai import ChatOpenAI
from langchain.callbacks import get_openai_callback

model = ChatOpenAI(temperature=0.7)

# æˆæœ¬è·Ÿè¸ª
with get_openai_callback() as cb:
    response = model.invoke("å†™ä¸€ä¸ª Python å‡½æ•°")
    print(f"Token ç”¨é‡: {cb.total_tokens}")
    print(f"æˆæœ¬: ${cb.total_cost}")

# ä¸åŒå‚æ•°å¯¹æ¯”
for temp in [0, 0.5, 1.0]:
    model = ChatOpenAI(temperature=temp)
    # æµ‹è¯•è¾“å‡ºå·®å¼‚
```
```

#### å‘¨ä¸‰ - é“¾å¼æç¤ºä¼˜åŒ– (3 å°æ—¶)
```
ä»»åŠ¡æ¸…å•:
â–¡ æç¤ºå·¥ç¨‹æœ€ä½³å®è·µ
  - æ¸…æ™°æŒ‡ä»¤ (30 åˆ†é’Ÿ)
  - Few-shot å­¦ä¹  (30 åˆ†é’Ÿ)
  - è§’è‰²æ‰®æ¼” (20 åˆ†é’Ÿ)

â–¡ æç¤ºä¼˜åŒ–
  - A/B æµ‹è¯• (30 åˆ†é’Ÿ)
  - æ•ˆæœè¯„ä¼° (20 åˆ†é’Ÿ)
  - è¿­ä»£æ”¹è¿› (20 åˆ†é’Ÿ)

ä»£ç ä»»åŠ¡:
```python
# åˆ›å»ºæ–‡ä»¶: 07_prompt_optimization.py
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

model = ChatOpenAI()

# ä¸åŒé£æ ¼çš„æç¤º
prompts = {
    "simple": "ç¿»è¯‘: {text}",
    "detailed": """è¯·å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆä¸­æ–‡ã€‚
ç¡®ä¿ç¿»è¯‘ï¼š
1. å‡†ç¡®è¡¨è¾¾åŸæ„
2. è‡ªç„¶æµç•…
3. é€‚åˆä¸­æ–‡é˜…è¯»ä¹ æƒ¯

æ–‡æœ¬: {text}""",
    "few_shot": """ç¿»è¯‘ç¤ºä¾‹ï¼š
"Hello" -> "ä½ å¥½"
"Goodbye" -> "å†è§"

ç°åœ¨ç¿»è¯‘: {text}"""
}

# æ¯”è¾ƒä¸åŒæç¤ºæ•ˆæœ
```
```

#### å‘¨å›› - Streaming ä¸æ‰¹å¤„ç† (3 å°æ—¶)
```
ä»»åŠ¡æ¸…å•:
â–¡ æµå¼è¾“å‡º
  - stream() æ–¹æ³• (30 åˆ†é’Ÿ)
  - Token çº§æµå¼ (30 åˆ†é’Ÿ)
  - å®æ—¶æ˜¾ç¤º (20 åˆ†é’Ÿ)

â–¡ æ‰¹å¤„ç†
  - batch() æ–¹æ³• (30 åˆ†é’Ÿ)
  - å¹¶è¡Œå¤„ç† (20 åˆ†é’Ÿ)
  - æ€§èƒ½å¯¹æ¯” (20 åˆ†é’Ÿ)

ä»£ç ä»»åŠ¡:
```python
# åˆ›å»ºæ–‡ä»¶: 08_streaming_batch.py
from langchain_openai import ChatOpenAI

model = ChatOpenAI()

# æµå¼è¾“å‡º
print("æµå¼è¾“å‡º:")
for chunk in model.stream("è®²ä¸€ä¸ªç¬‘è¯"):
    print(chunk.content, end="", flush=True)

print("\næ‰¹å¤„ç†:")
inputs = ["ç¬‘è¯ 1", "ç¬‘è¯ 2", "ç¬‘è¯ 3"]
results = model.batch(inputs)
for result in results:
    print(result.content)
```
```

#### å‘¨äº” - ç¬¬ä¸€é˜¶æ®µæ€»ç»“ä¸æµ‹è¯• (3 å°æ—¶)
```
ä»»åŠ¡æ¸…å•:
â–¡ çŸ¥è¯†æ€»ç»“
  - åˆ›å»ºæ¦‚å¿µå¯¼å›¾ (30 åˆ†é’Ÿ)
  - æ•´ç†å¸¸ç”¨ä»£ç  (30 åˆ†é’Ÿ)
  - æ€»ç»“æœ€ä½³å®è·µ (20 åˆ†é’Ÿ)

â–¡ ç»¼åˆæµ‹è¯•é¡¹ç›®

é¡¹ç›®: æ„å»ºä¸€ä¸ª"æ™ºèƒ½å®¢æœ"ç³»ç»Ÿ
è¦æ±‚:
- æ”¯æŒå¤šè½®å¯¹è¯
- ç»´æŠ¤å¯¹è¯å†å²
- å¤„ç†å¸¸è§é—®é¢˜
- è¿”å›ç»“æ„åŒ–ä¿¡æ¯
- ä¼˜åŒ–æˆæœ¬

æ£€æŸ¥æ¸…å•:
- â–¡ ç¯å¢ƒé…ç½®æ­£ç¡®
- â–¡ æ‰€æœ‰ä»£ç èƒ½å¤Ÿè¿è¡Œ
- â–¡ ç†è§£æ ¸å¿ƒæ¦‚å¿µ
- â–¡ å®Œæˆä¸¤ä¸ªæµ‹è¯•é¡¹ç›®
- â–¡ å‡†å¤‡è¿›å…¥ç¬¬äºŒé˜¶æ®µ
```

---

## ğŸ”— ç¬¬äºŒé˜¶æ®µï¼šé“¾ä¸ç»„åˆï¼ˆç¬¬ 3-4 å‘¨ï¼‰

### ç¬¬ 3 å‘¨ï¼šLCEL ä¸ Runnable

#### å‘¨ä¸€ - Runnable æ¥å£æ·±å…¥ (3 å°æ—¶)
```
ä»»åŠ¡æ¸…å•:
â–¡ ç†è§£ Runnable
  - ä»€ä¹ˆæ˜¯ Runnable (30 åˆ†é’Ÿ)
  - æ ¸å¿ƒæ–¹æ³•è¯¦è§£ (40 åˆ†é’Ÿ)
  - Runnable è®¾è®¡æ¨¡å¼ (20 åˆ†é’Ÿ)

â–¡ æ ¸å¿ƒæ–¹æ³•å®è·µ
  - invoke() åŒæ­¥è°ƒç”¨ (30 åˆ†é’Ÿ)
  - batch() æ‰¹é‡å¤„ç† (30 åˆ†é’Ÿ)
  - stream() æµå¼å¤„ç† (20 åˆ†é’Ÿ)

ä»£ç ä»»åŠ¡:
```python
# åˆ›å»ºæ–‡ä»¶: 09_runnable_interface.py
from langchain_core.runnables import Runnable
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

model = ChatOpenAI()
prompt = ChatPromptTemplate.from_template("è®²ä¸€ä¸ªå…³äº{topic}çš„ç¬‘è¯")

# æ‰€æœ‰è¿™äº›éƒ½æ˜¯ Runnable
print("Model invoke:", model.invoke("Hello"))
print("Prompt invoke:", prompt.invoke({"topic": "Python"}))

# å°è¯• batch
results = model.batch(["Hello", "Hi", "Hey"])
print("Batch results:", results)

# å°è¯• stream
for chunk in model.stream("Tell a joke"):
    print(chunk, end="")
```
```

#### å‘¨äºŒ - LCEL ç®¡é“æ“ä½œ (3 å°æ—¶)
```
ä»»åŠ¡æ¸…å•:
â–¡ LCEL è¯­æ³•
  - ç®¡é“æ“ä½œç¬¦ (|) (30 åˆ†é’Ÿ)
  - ç»„åˆå¤šä¸ª Runnable (30 åˆ†é’Ÿ)
  - å­—å…¸å¼è¾“å…¥è¾“å‡º (20 åˆ†é’Ÿ)

â–¡ å®é™…åº”ç”¨
  - æ„å»ºç®€å•é“¾ (30 åˆ†é’Ÿ)
  - æ„å»ºå¤æ‚é“¾ (30 åˆ†é’Ÿ)

ä»£ç ä»»åŠ¡:
```python
# åˆ›å»ºæ–‡ä»¶: 10_lcel_basics.py
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

# æœ€ç®€å•çš„é“¾
prompt = ChatPromptTemplate.from_template("ç¿»è¯‘: {text}")
model = ChatOpenAI()
parser = StrOutputParser()

chain = prompt | model | parser
result = chain.invoke({"text": "Hello"})
print(result)

# æ›´å¤æ‚çš„é“¾
from langchain_core.runnables import RunnablePassthrough

chain = (
    {"input": RunnablePassthrough()}
    | prompt
    | model
    | parser
)

result = chain.invoke("Test")
```
```

#### å‘¨ä¸‰ - RunnableParallel ä¸åˆ†æ”¯ (3 å°æ—¶)
```
ä»»åŠ¡æ¸…å•:
â–¡ å¹¶è¡Œæ‰§è¡Œ
  - RunnableParallel (40 åˆ†é’Ÿ)
  - ç‹¬ç«‹ä»»åŠ¡å¹¶è¡Œ (40 åˆ†é’Ÿ)

â–¡ æ¡ä»¶åˆ†æ”¯
  - RunnableBranch (30 åˆ†é’Ÿ)
  - åŠ¨æ€è·¯ç”± (30 åˆ†é’Ÿ)

ä»£ç ä»»åŠ¡:
```python
# åˆ›å»ºæ–‡ä»¶: 11_parallel_branch.py
from langchain_core.runnables import RunnableParallel, RunnableBranch
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

model = ChatOpenAI()

# å¹¶è¡Œæ‰§è¡Œ
parallel = RunnableParallel(
    grammar_check=ChatPromptTemplate.from_template(
        "æ£€æŸ¥è¯­æ³•: {text}"
    ) | model,
    tone_analysis=ChatPromptTemplate.from_template(
        "åˆ†æè¯­æ°”: {text}"
    ) | model
)

result = parallel.invoke({"text": "This is a test."})

# åˆ†æ”¯
branch = RunnableBranch(
    (lambda x: "Chinese" in x["lang"], ChatPromptTemplate.from_template(
        "ç¿»è¯‘æˆä¸­æ–‡: {text}"
    ) | model),
    (lambda x: "English" in x["lang"], ChatPromptTemplate.from_template(
        "Translate to English: {text}"
    ) | model),
    ChatPromptTemplate.from_template("Unknown language") | model
)
```
```

#### å‘¨å›› - é”™è¯¯å¤„ç†ä¸è°ƒè¯• (3 å°æ—¶)
```
ä»»åŠ¡æ¸…å•:
â–¡ å¼‚å¸¸å¤„ç†
  - try-except æ¨¡å¼ (30 åˆ†é’Ÿ)
  - é‡è¯•æœºåˆ¶ (30 åˆ†é’Ÿ)
  - é™çº§æ–¹æ¡ˆ (20 åˆ†é’Ÿ)

â–¡ è°ƒè¯•å·¥å…·
  - æ—¥å¿—è®°å½• (30 åˆ†é’Ÿ)
  - ä¸­é—´æ­¥éª¤è¿½è¸ª (20 åˆ†é’Ÿ)

ä»£ç ä»»åŠ¡:
```python
# åˆ›å»ºæ–‡ä»¶: 12_error_handling.py
from langchain_core.runnables import RunnableRetry
from langchain_openai import ChatOpenAI
import logging

logging.basicConfig(level=logging.DEBUG)

model = ChatOpenAI()

# é‡è¯•æœºåˆ¶
retry_chain = model.with_retry(max_attempts=3)

try:
    result = retry_chain.invoke("Test", timeout=10)
except Exception as e:
    print(f"Error: {e}")
    # é™çº§æ–¹æ¡ˆ
    result = "Default response"
```
```

#### å‘¨äº” - ç¬¬äºŒå‘¨å›é¡¾ (3 å°æ—¶)
```
ç»¼åˆé¡¹ç›®: æ„å»ºä¸€ä¸ªæ–‡æœ¬å¤„ç†ç®¡é“

åŠŸèƒ½:
- è¯­æ³•æ£€æŸ¥
- è¯­æ°”åˆ†æ
- è¦ç‚¹æå–
- é•¿åº¦ä¼˜åŒ–

æ£€æŸ¥æ¸…å•:
- â–¡ ç†è§£ Runnable æ¥å£çš„æ‰€æœ‰æ–¹æ³•
- â–¡ èƒ½ä½¿ç”¨ LCEL è¯­æ³•ç¼–å†™é“¾
- â–¡ èƒ½å¤„ç†å¹¶è¡Œå’Œåˆ†æ”¯
- â–¡ èƒ½è¿›è¡Œé”™è¯¯å¤„ç†
```

### ç¬¬ 4 å‘¨ï¼šé«˜çº§ LCEL ä¸æœ€ä½³å®è·µ

#### å‘¨ä¸€ - RunnablePassthrough ä¸å­—å…¸æ“ä½œ (3 å°æ—¶)
```
ä»»åŠ¡æ¸…å•:
â–¡ æ•°æ®æµå¤„ç†
  - RunnablePassthrough (30 åˆ†é’Ÿ)
  - å­—å…¸è¾“å…¥è¾“å‡º (30 åˆ†é’Ÿ)
  - æ•°æ®è½¬æ¢ (20 åˆ†é’Ÿ)

ä»£ç ä»»åŠ¡:
```python
# åˆ›å»ºæ–‡ä»¶: 13_passthrough.py
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

model = ChatOpenAI()

# ä¿ç•™åŸå§‹è¾“å…¥
chain = (
    {"text": RunnablePassthrough(), "language": lambda x: "English"}
    | ChatPromptTemplate.from_template(
        "Translate to {language}: {text}"
    )
    | model
)

result = chain.invoke("Hello")
```
```

#### å‘¨äºŒ - Lambda ä¸è‡ªå®šä¹‰å‡½æ•° (3 å°æ—¶)
```
ä»»åŠ¡æ¸…å•:
â–¡ å‡½æ•°è½¬æ¢
  - lambda å‡½æ•° (30 åˆ†é’Ÿ)
  - è‡ªå®šä¹‰å‡½æ•°è½¬ä¸º Runnable (30 åˆ†é’Ÿ)
  - æ•°æ®é¢„å¤„ç† (20 åˆ†é’Ÿ)

ä»£ç ä»»åŠ¡:
```python
# åˆ›å»ºæ–‡ä»¶: 14_custom_functions.py
from langchain_core.runnables import RunnableLambda
from langchain_openai import ChatOpenAI

model = ChatOpenAI()

# è‡ªå®šä¹‰é¢„å¤„ç†
def preprocess(text):
    return text.strip().lower()

# è½¬æ¢ä¸º Runnable
preprocess_runnable = RunnableLambda(preprocess)

chain = (
    preprocess_runnable
    | ChatPromptTemplate.from_template("ç¿»è¯‘: {text}")
    | model
)
```
```

#### å‘¨ä¸‰ - é“¾çš„å¯è§‚æµ‹æ€§ä¸è¿½è¸ª (3 å°æ—¶)
```
ä»»åŠ¡æ¸…å•:
â–¡ è°ƒè¯•å·¥å…·
  - ä¸­é—´æ­¥éª¤æ‰“å° (30 åˆ†é’Ÿ)
  - å›è°ƒç³»ç»Ÿ (30 åˆ†é’Ÿ)
  - LangSmith é›†æˆ (20 åˆ†é’Ÿ)

ä»£ç ä»»åŠ¡:
```python
# åˆ›å»ºæ–‡ä»¶: 15_observability.py
from langchain.callbacks import StdOutCallbackHandler
from langchain_openai import ChatOpenAI

# å¯ç”¨è¯¦ç»†æ—¥å¿—
callbacks = [StdOutCallbackHandler()]
model = ChatOpenAI(callbacks=callbacks)

result = model.invoke("Test", callbacks=callbacks)
```
```

#### å‘¨å›› - å¼‚æ­¥ç¼–ç¨‹åŸºç¡€ (3 å°æ—¶)
```
ä»»åŠ¡æ¸…å•:
â–¡ å¼‚æ­¥æ–¹æ³•
  - ainvoke() (30 åˆ†é’Ÿ)
  - astream() (30 åˆ†é’Ÿ)
  - abatch() (20 åˆ†é’Ÿ)

ä»£ç ä»»åŠ¡:
```python
# åˆ›å»ºæ–‡ä»¶: 16_async_basics.py
import asyncio
from langchain_openai import ChatOpenAI

async def main():
    model = ChatOpenAI()

    # å¼‚æ­¥è°ƒç”¨
    result = await model.ainvoke("Hello")
    print(result)

    # å¼‚æ­¥æµå¼
    async for chunk in model.astream("Tell a joke"):
        print(chunk.content, end="")

asyncio.run(main())
```
```

#### å‘¨äº” - ç¬¬äºŒé˜¶æ®µé¡¹ç›® (3 å°æ—¶)
```
ç»¼åˆé¡¹ç›®: æ„å»ºä¸€ä¸ª"å†…å®¹åˆ†æç®¡é“"

åŠŸèƒ½:
1. æ¥æ”¶æ–‡æœ¬è¾“å…¥
2. å¹¶è¡Œå¤„ç†:
   - å…³é”®è¯æå–
   - æƒ…æ„Ÿåˆ†æ
   - é•¿åº¦è®¡ç®—
3. èšåˆç»“æœ
4. ç”ŸæˆæŠ¥å‘Š

è¦æ±‚:
- ä½¿ç”¨ LCEL è¯­æ³•
- å®ç°å¹¶è¡Œå¤„ç†
- å¤„ç†é”™è¯¯æƒ…å†µ
- æ”¯æŒæµå¼è¾“å‡º

æ£€æŸ¥æ¸…å•:
- â–¡ ç†è§£ LCEL æ‰€æœ‰æ“ä½œ
- â–¡ èƒ½å¤„ç†å¤æ‚çš„æ•°æ®æµ
- â–¡ èƒ½è¿›è¡Œé”™è¯¯å¤„ç†
- â–¡ èƒ½ä½¿ç”¨å¼‚æ­¥æ–¹æ³•
- â–¡ å‡†å¤‡è¿›å…¥ç¬¬ä¸‰é˜¶æ®µ
```

---

## ğŸ“– ç®€åŒ–ç‰ˆå‘¨è®¡åˆ’è¡¨ï¼ˆç¬¬ 5-20 å‘¨ï¼‰

ç”±äºç¯‡å¹…é™åˆ¶ï¼Œä»¥ä¸‹æ˜¯ç®€åŒ–çš„å‘¨è®¡åˆ’è¡¨ã€‚è¯¦ç»†ç‰ˆæœ¬è¯·å‚è€ƒå®Œæ•´è®¡åˆ’æ–‡æ¡£ã€‚

### ç¬¬ä¸‰é˜¶æ®µï¼šæ•°æ®ç®¡ç†ä¸ RAGï¼ˆç¬¬ 5-7 å‘¨ï¼‰

| å‘¨æ¬¡ | å‘¨ä¸€ | å‘¨äºŒ | å‘¨ä¸‰ | å‘¨å›› | å‘¨äº” |
|------|------|------|------|------|------|
| ç¬¬ 5 å‘¨ | æ–‡æ¡£åŠ è½½ | PDF å¤„ç† | æ–‡æœ¬åˆ†å‰² | å…ƒæ•°æ®ç®¡ç† | é¡¹ç›®å°ç»“ |
| ç¬¬ 6 å‘¨ | åµŒå…¥æ¨¡å‹ | å‘é‡åŒ– | å‘é‡å­˜å‚¨ | ç›¸ä¼¼æ€§æœç´¢ | é¡¹ç›®å°ç»“ |
| ç¬¬ 7 å‘¨ | æ£€ç´¢å™¨ | å¤šå±‚æ£€ç´¢ | RAG å®ç° | æ€§èƒ½ä¼˜åŒ– | **RAG é¡¹ç›®** |

### ç¬¬å››é˜¶æ®µï¼šå·¥å…·ä¸ä»£ç†ï¼ˆç¬¬ 8-10 å‘¨ï¼‰

| å‘¨æ¬¡ | å‘¨ä¸€ | å‘¨äºŒ | å‘¨ä¸‰ | å‘¨å›› | å‘¨äº” |
|------|------|------|------|------|------|
| ç¬¬ 8 å‘¨ | å·¥å…·å®šä¹‰ | å·¥å…·è°ƒç”¨ | æ¨¡å‹ç»‘å®š | å·¥å…·éªŒè¯ | é¡¹ç›®å°ç»“ |
| ç¬¬ 9 å‘¨ | ä»£ç†æ¡†æ¶ | å·¥å…·è°ƒç”¨ä»£ç† | å¤šå·¥å…·ä»£ç† | ä»£ç†è°ƒè¯• | é¡¹ç›®å°ç»“ |
| ç¬¬ 10 å‘¨ | ReAct ä»£ç† | è‡ªå®šä¹‰ä»£ç† | ä»£ç†è®°å¿† | é«˜çº§æ¨¡å¼ | **ä»£ç†é¡¹ç›®** |

### ç¬¬äº”é˜¶æ®µï¼šLangGraphï¼ˆç¬¬ 11-13 å‘¨ï¼‰

| å‘¨æ¬¡ | å‘¨ä¸€ | å‘¨äºŒ | å‘¨ä¸‰ | å‘¨å›› | å‘¨äº” |
|------|------|------|------|------|------|
| ç¬¬ 11 å‘¨ | å›¾åŸºç¡€ | çŠ¶æ€ç®¡ç† | èŠ‚ç‚¹ä¸è¾¹ | æ¡ä»¶è·¯ç”± | é¡¹ç›®å°ç»“ |
| ç¬¬ 12 å‘¨ | æ¶ˆæ¯çŠ¶æ€ | å­å›¾ | æŒä¹…åŒ– | å¯è§†åŒ– | é¡¹ç›®å°ç»“ |
| ç¬¬ 13 å‘¨ | RAG å›¾ | å›¾è°ƒè¯• | æ€§èƒ½ä¼˜åŒ– | æ‰©å±•æ€§ | **LangGraph é¡¹ç›®** |

### ç¬¬å…­é˜¶æ®µï¼šé«˜çº§åº”ç”¨ï¼ˆç¬¬ 14-16 å‘¨ï¼‰

| å‘¨æ¬¡ | å‘¨ä¸€ | å‘¨äºŒ | å‘¨ä¸‰ | å‘¨å›› | å‘¨äº” |
|------|------|------|------|------|------|
| ç¬¬ 14 å‘¨ | å¤šä»£ç† | ä»£ç†é€šä¿¡ | ä¸»ç®¡æ¨¡å¼ | åä½œç­–ç•¥ | é¡¹ç›®å°ç»“ |
| ç¬¬ 15 å‘¨ | æµå¼å¤„ç† | å¼‚æ­¥ç¼–ç¨‹ | å®æ—¶äº¤äº’ | å¹¶å‘ä¼˜åŒ– | é¡¹ç›®å°ç»“ |
| ç¬¬ 16 å‘¨ | è¯„ä¼°ä¸ç›‘æ§ | è‡ªåŠ¨è¯„ä¼° | LangSmith | æ€§èƒ½ç›‘æ§ | **é«˜çº§åº”ç”¨é¡¹ç›®** |

### ç¬¬ä¸ƒé˜¶æ®µï¼šç»¼åˆé¡¹ç›®ï¼ˆç¬¬ 17-20 å‘¨ï¼‰

| å‘¨æ¬¡ | å†…å®¹ |
|------|------|
| ç¬¬ 17 å‘¨ | é¡¹ç›®é€‰æ‹©ä¸éœ€æ±‚åˆ†æ |
| ç¬¬ 18 å‘¨ | æ ¸å¿ƒåŠŸèƒ½å¼€å‘ |
| ç¬¬ 19 å‘¨ | é›†æˆã€ä¼˜åŒ–ä¸æµ‹è¯• |
| ç¬¬ 20 å‘¨ | éƒ¨ç½²ã€è¯„ä¼°ä¸æ€»ç»“ |

---

## ğŸ“‹ æ¯å‘¨æ—¶é—´åˆ†é…å»ºè®®

### æ¨èæ¯å‘¨ 20 å°æ—¶å®‰æ’

```
å‘¨ä¸€-å‘¨å››: å„ 3 å°æ—¶ (å…± 12 å°æ—¶)
â”œâ”€ å­¦ä¹ æ–°æ¦‚å¿µ: 1.5 å°æ—¶
â”œâ”€ ä»£ç å®è·µ: 1 å°æ—¶
â””â”€ ç»ƒä¹ ä¸å¤ä¹ : 0.5 å°æ—¶

å‘¨äº”: 3 å°æ—¶
â”œâ”€ æœ¬å‘¨å›é¡¾: 1 å°æ—¶
â”œâ”€ ç»¼åˆé¡¹ç›®: 1.5 å°æ—¶
â””â”€ çŸ¥è¯†æ•´ç†: 0.5 å°æ—¶

å‘¨æœ«: 2 å°æ—¶
â”œâ”€ é˜…è¯»è¡¥å……èµ„æ–™: 1 å°æ—¶
â””â”€ ç¤¾åŒºäº¤æµ: 1 å°æ—¶
```

### çµæ´»è°ƒæ•´å»ºè®®

- **åŸºç¡€å·®çš„åŒå­¦**: æ¯ä¸ªé˜¶æ®µå»¶é•¿ 1 å‘¨
- **åŸºç¡€å¥½çš„åŒå­¦**: å¯ä»¥å‹ç¼©åˆ° 15 å‘¨
- **æœ‰å·¥ä½œçš„åŒå­¦**: å¹³å‡æ¯å¤© 1.5 å°æ—¶ï¼Œå»¶é•¿åˆ° 6-7 ä¸ªæœˆ

---

## ğŸ¯ æ¯å‘¨å­¦ä¹ ç›®æ ‡æ£€æŸ¥

### ç¬¬ä¸€é˜¶æ®µæ£€æŸ¥æ¸…å•
```
ç¬¬ 1 å‘¨ç»“æŸ:
â–¡ èƒ½åˆ›å»º OpenAI æ¨¡å‹å®ä¾‹
â–¡ ç†è§£ PromptTemplate å’Œ ChatPromptTemplate
â–¡ èƒ½ä½¿ç”¨ OutputParser è§£æç»“æœ
â–¡ èƒ½å¤„ç†åŸºç¡€é”™è¯¯

ç¬¬ 2 å‘¨ç»“æŸ:
â–¡ èƒ½ç»´æŠ¤å¤šè½®å¯¹è¯å†å²
â–¡ ç†è§£ Token å’Œæˆæœ¬è®¡ç®—
â–¡ èƒ½ä¼˜åŒ–æç¤ºè¯
â–¡ èƒ½ä½¿ç”¨ stream å’Œ batch æ–¹æ³•
```

### ç¬¬äºŒé˜¶æ®µæ£€æŸ¥æ¸…å•
```
ç¬¬ 3 å‘¨ç»“æŸ:
â–¡ ç†è§£ Runnable æ¥å£çš„æ‰€æœ‰æ ¸å¿ƒæ–¹æ³•
â–¡ èƒ½ä½¿ç”¨ LCEL è¯­æ³•æ„å»ºç®€å•é“¾
â–¡ èƒ½ä½¿ç”¨ RunnableParallel å¹¶è¡Œå¤„ç†
â–¡ èƒ½ä½¿ç”¨ RunnableBranch æ¡ä»¶åˆ†æ”¯

ç¬¬ 4 å‘¨ç»“æŸ:
â–¡ èƒ½å¤„ç†å¤æ‚çš„æ•°æ®æµ
â–¡ èƒ½å®ç°è‡ªå®šä¹‰è½¬æ¢å‡½æ•°
â–¡ èƒ½è°ƒè¯•å’Œè¿½è¸ªé“¾çš„æ‰§è¡Œ
â–¡ èƒ½ä½¿ç”¨å¼‚æ­¥æ–¹æ³•
```

ï¼ˆä»¥æ­¤ç±»æ¨ï¼Œæ¯ä¸ªé˜¶æ®µéƒ½æœ‰è¯¦ç»†çš„æ£€æŸ¥æ¸…å•ï¼‰

---

## ğŸš€ åŠ é€Ÿå­¦ä¹ æŠ€å·§

### 1. ä»£ç åº“ç»„ç»‡
```
LearnLangChain/
â”œâ”€â”€ week01/
â”‚   â”œâ”€â”€ 01_llm_basics.py
â”‚   â”œâ”€â”€ 02_prompt_templates.py
â”‚   â””â”€â”€ 03_messages_parsing.py
â”œâ”€â”€ week02/
â”œâ”€â”€ ...
â”œâ”€â”€ projects/
â”‚   â”œâ”€â”€ project_rag.py
â”‚   â”œâ”€â”€ project_agent.py
â”‚   â””â”€â”€ project_langgraph.py
â”œâ”€â”€ notes/
â”‚   â”œâ”€â”€ week01_summary.md
â”‚   â””â”€â”€ concepts.md
â””â”€â”€ LANGCHAIN_KNOWLEDGE_MAP.md
```

### 2. å­¦ä¹ è®°å½•æ¨¡æ¿

æ¯å‘¨åˆ›å»ºä¸€ä¸ªå­¦ä¹ è®°å½•ï¼š
```markdown
# ç¬¬ X å‘¨å­¦ä¹ æ€»ç»“

## æœ¬å‘¨å­¦ä¹ å†…å®¹
- æ¦‚å¿µ 1: ...
- æ¦‚å¿µ 2: ...

## å…³é”®æ”¶è·
- ...

## é‡åˆ°çš„é—®é¢˜
- é—®é¢˜ 1: è§£å†³æ–¹æ¡ˆ
- é—®é¢˜ 2: è§£å†³æ–¹æ¡ˆ

## ä»£ç ç¤ºä¾‹
```python
# å…³é”®ä»£ç ç‰‡æ®µ
```

## ä¸‹å‘¨å‡†å¤‡
- ...
```

### 3. è°ƒè¯•æŠ€å·§

```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)

# æ‰“å°ä¸­é—´ç»“æœ
from langchain.callbacks import StdOutCallbackHandler
chain.invoke(input, config={"callbacks": [StdOutCallbackHandler()]})

# ä½¿ç”¨ LangSmith è¿½è¸ª
export LANGCHAIN_TRACING_V2=true
export LANGCHAIN_API_KEY="your-key"
```

### 4. å¿«é€Ÿå‚è€ƒ

å»ºç«‹ä¸€ä¸ª `quick_reference.md` æ–‡ä»¶ï¼š

```markdown
# LangChain å¿«é€Ÿå‚è€ƒ

## æœ€å¸¸ç”¨ä»£ç ç‰‡æ®µ
```python
# åŸºç¡€é“¾
chain = prompt | model | parser

# å¹¶è¡Œå¤„ç†
parallel = RunnableParallel(a=chain_a, b=chain_b)

# æ¡ä»¶åˆ†æ”¯
branch = RunnableBranch(
    (condition, chain_if_true),
    default_chain
)
```

## å¸¸è§é”™è¯¯ä¸è§£å†³
- é”™è¯¯ 1: ...
- é”™è¯¯ 2: ...
```

---

## ğŸ“š æ¨èå­¦ä¹ èµ„æº

### å®˜æ–¹èµ„æº
- ğŸ“– LangChain Python æ–‡æ¡£: https://python.langchain.com/
- ğŸ“ LangGraph æ–‡æ¡£: https://langchain-ai.github.io/langgraph/
- ğŸ’» GitHub ç¤ºä¾‹: https://github.com/langchain-ai/langchain/tree/master/examples

### è§†é¢‘æ•™ç¨‹
- YouTube: LangChain Crash Course
- YouTube: Building AI Apps with LangChain
- å®˜æ–¹æ¼”è®²ä¸æ•™ç¨‹

### äº¤äº’å¼å­¦ä¹ 
- LangChain å®˜æ–¹ç¬”è®°æœ¬ç¤ºä¾‹
- DeepLearning.AI LangChain è¯¾ç¨‹

### ç¤¾åŒºæ”¯æŒ
- GitHub Discussions
- Discord ç¤¾ç¾¤
- Stack Overflow (langchain æ ‡ç­¾)

---

## âœ… æœ€ç»ˆæ£€æŸ¥æ¸…å•

å­¦ä¹ å®Œæˆåï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š

**åŸºç¡€èƒ½åŠ›**
- â˜ åˆ›å»ºå’Œé…ç½® LLM
- â˜ è®¾è®¡æœ‰æ•ˆçš„æç¤ºè¯
- â˜ å¤„ç†æ¨¡å‹è¾“å‡º
- â˜ ç®¡ç†å¯¹è¯å†å²

**è¿›é˜¶èƒ½åŠ›**
- â˜ ä½¿ç”¨ LCEL æ„å»ºå¤æ‚é“¾
- â˜ å®ç° RAG ç³»ç»Ÿ
- â˜ åˆ›å»ºå·¥å…·å’Œä»£ç†
- â˜ ä½¿ç”¨ LangGraph è®¾è®¡å·¥ä½œæµ

**ä¸“ä¸šèƒ½åŠ›**
- â˜ æ„å»ºå¤šä»£ç†ç³»ç»Ÿ
- â˜ å®ç°æµå¼å’Œå¼‚æ­¥å¤„ç†
- â˜ è¯„ä¼°å’Œä¼˜åŒ–ç³»ç»Ÿ
- â˜ éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ

**é¡¹ç›®ç»éªŒ**
- â˜ å®Œæˆ 3+ ä¸ªå®é™…é¡¹ç›®
- â˜ å¤„ç†çœŸå®ä¸–ç•Œçš„æ•°æ®å’Œéœ€æ±‚
- â˜ ä¼˜åŒ–æ€§èƒ½å’Œæˆæœ¬
- â˜ å‚ä¸ç¤¾åŒºè´¡çŒ®

---

ç¥å­¦ä¹ é¡ºåˆ©ï¼æœ‰ä»»ä½•é—®é¢˜ï¼Œæ¬¢è¿æŸ¥çœ‹çŸ¥è¯†å›¾è°±æˆ–è”ç³»ç¤¾åŒºã€‚ğŸš€
